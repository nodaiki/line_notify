# Seminer.py
import os, re, requests
from bs4 import BeautifulSoup

LINE_TOKEN    = os.getenv("LINE_TOKEN")
DENSUKE_URL   = "https://densuke.biz/list?cd=dxncu2PesTNses2c"
SNAPSHOT_HTML = os.getenv("SNAPSHOT_HTML") or "prev.html"  # ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; DensukeWatcher/1.0; +https://github.com/)",
}

def fetch_html() -> str:
    r = requests.get(DENSUKE_URL, headers=HEADERS, timeout=20)
    r.raise_for_status()
    return r.text

def norm(s: str) -> str:
    return re.sub(r"\s+", " ", s).strip()

def rows_from_html(html: str):
    """
    #listtable ã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ (è¡Œã‚­ãƒ¼, æœ€çµ‚ã‚»ãƒ«ã®è¨˜å·) ã§æŠ½å‡º
    - è¡Œã‚­ãƒ¼: 1åˆ—ç›®(ä¾‹: "13æ—¥ï¼ˆæ°´ï¼‰14ï¼š00ï½")
    - æœ€çµ‚ã‚»ãƒ«ã« 'Ã—' ã‚’å«ã‚€ãªã‚‰ 'Ã—' ã‚’è¿”ã™
    """
    soup = BeautifulSoup(html, "html.parser")
    table = soup.select_one("#listtable")
    if not table:
        print("[WARN] #listtable ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸æ§‹é€ ãŒå¤‰ã‚ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        return set(), {}
    rows = table.find_all("tr")
    keys, lastmap = set(), {}
    for tr in rows[1:]:  # ãƒ˜ãƒƒãƒ€è¡Œã‚¹ã‚­ãƒƒãƒ—
        cells = tr.find_all(["td","th"])
        if not cells or not tr.find("td"):
            continue
        first = norm(cells[0].get_text(" ", strip=True))
        if not first or set(first) == {"-"}:  # ä»•åˆ‡ã‚Šè¡Œ "------" ã¯é™¤å¤–
            continue
        last_text = norm(cells[-1].get_text(" ", strip=True))
        last = "Ã—" if "Ã—" in last_text else last_text
        keys.add(first)
        lastmap[first] = last
    return keys, lastmap

def chunk_messages(header: str, lines: list[str], limit: int = 4700) -> list[str]:
    current = header
    messages = []
    for line in lines:
        candidate = current + f"\nãƒ»{line}"
        if len(candidate) > limit:
            messages.append(current)
            current = header + f"\nãƒ»{line}"
        else:
            current = candidate
    if current.strip():
        messages.append(current)
    return messages

def send_broadcast_texts(texts: list[str]):
    if not LINE_TOKEN:
        print("[ERROR] ç’°å¢ƒå¤‰æ•° LINE_TOKEN ãŒæœªè¨­å®šã§ã™ï¼ˆMessaging API ã®ãƒãƒ£ãƒãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰ã€‚")
        return
    url = "https://api.line.me/v2/bot/message/broadcast"  # â† Messaging API
    headers = {"Authorization": f"Bearer {LINE_TOKEN}", "Content-Type": "application/json"}
    for i in range(0, len(texts), 5):  # 1å›ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§æœ€å¤§5ä»¶
        batch = [{"type":"text","text":t} for t in texts[i:i+5]]
        res = requests.post(url, headers=headers, json={"messages": batch}, timeout=20)
        print("LINE API:", res.status_code, res.text)

def main():
    try:
        new_html = fetch_html()
    except Exception as e:
        print(f"[ERROR] HTMLå–å¾—ã«å¤±æ•—: {e}")
        return

    new_keys, new_last = rows_from_html(new_html)

    # åˆå›ã¯ä¿å­˜ã®ã¿
    if not os.path.exists(SNAPSHOT_HTML):
        with open(SNAPSHOT_HTML, "w", encoding="utf-8") as f:
            f.write(new_html)
        print(f"[INFO] åˆå›ä¿å­˜ã®ã¿ï¼ˆè¡Œ {len(new_keys)} ä»¶ï¼‰")
        return

    with open(SNAPSHOT_HTML, "r", encoding="utf-8") as f:
        old_html = f.read()
    old_keys, _ = rows_from_html(old_html)

    added = sorted(new_keys - old_keys)
    print(f"[INFO] æ—§{len(old_keys)} / æ–°{len(new_keys)} / è¿½åŠ {len(added)}")

    notify_lines = [k for k in added if new_last.get(k, "") != "Ã—"]
    print(f"[INFO] é€šçŸ¥å¯¾è±¡ï¼ˆÃ—é™¤å¤–ï¼‰: {len(notify_lines)} ä»¶")
    if notify_lines:
        header = "ğŸ“… æ–°è¦æ ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ"
        messages = chunk_messages(header, notify_lines)
        send_broadcast_texts(messages)
    else:
        print("[INFO] é€šçŸ¥å¯¾è±¡ã®è¿½åŠ ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    with open(SNAPSHOT_HTML, "w", encoding="utf-8") as f:
        f.write(new_html)

if __name__ == "__main__":
    main()
